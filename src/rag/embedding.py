import os
import json
import glob
from typing import List, Dict, Any, Tuple, Optional
from pathlib import Path
from langchain_pinecone import PineconeEmbeddings
from pinecone import Pinecone, ServerlessSpec
from dotenv import load_dotenv
import time
import pickle
import threading
from datetime import datetime, timedelta
from abc import ABC, abstractmethod
from dataclasses import dataclass

load_dotenv(verbose=True)

@dataclass
class EmbeddingConfig:
    """ì„ë² ë”© ê´€ë ¨ ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    pinecone_api_key: str
    embedding_model: str = "multilingual-e5-large"
    index_name: str = "openbadges"
    cloud: str = "aws"
    region: str = "us-east-1"
    backup_retention_minutes: int = 30
    backup_dir: str = "backup/deleted_vectors"
    
    @classmethod
    def from_env(cls) -> 'EmbeddingConfig':
        """í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì •ì„ ë¡œë“œ"""
        pinecone_api_key = os.environ.get("PINECONE_API_KEY")
        if not pinecone_api_key:
            raise ValueError("PINECONE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        return cls(
            pinecone_api_key=pinecone_api_key,
            embedding_model=os.environ.get("EMBEDDING_MODEL", "multilingual-e5-large"),
            index_name=os.environ.get("PINECONE_INDEX_NAME", "openbadges"),
            cloud=os.environ.get("PINECONE_CLOUD", "aws"),
            region=os.environ.get("PINECONE_REGION", "us-east-1"),
            backup_retention_minutes=int(os.environ.get("BACKUP_RETENTION_MINUTES", "30")),
            backup_dir=os.environ.get("BACKUP_DIR", "backup/deleted_vectors")
        )

class PineconeManager:
    """Pinecone ì—°ê²° ë° ì¸ë±ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: EmbeddingConfig):
        self.config = config
        self.pc = Pinecone(api_key=config.pinecone_api_key)
        self._index = None
        
    def get_index(self):
        """Pinecone ì¸ë±ìŠ¤ ë°˜í™˜ (lazy loading)"""
        if self._index is None:
            self._initialize_index()
            self._index = self.pc.Index(self.config.index_name)
        return self._index
    
    def _initialize_index(self):
        """Pinecone ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
        spec = ServerlessSpec(cloud=self.config.cloud, region=self.config.region)
        
        if self.config.index_name not in self.pc.list_indexes().names():
            # ì„ë² ë”© ì°¨ì›ì„ ì–»ê¸° ìœ„í•´ ì„ì‹œ ì„ë² ë”© ê°ì²´ ìƒì„±
            temp_embeddings = PineconeEmbeddings(
                model=self.config.embedding_model,
                pinecone_api_key=self.config.pinecone_api_key
            )
            
            self.pc.create_index(
                name=self.config.index_name,
                dimension=temp_embeddings.dimension,
                metric="cosine",
                spec=spec
            )
            # ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            while not self.pc.describe_index(self.config.index_name).status['ready']:
                time.sleep(1)

class VectorBackupManager:
    """ë²¡í„° ë°±ì—… ë° ë³µì› ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: EmbeddingConfig):
        self.config = config
        self._memory_backup = {}
        
    def backup_vector(self, vector_id: str, namespace: str, vector_data: Dict[str, Any], 
                     method: str = "memory"):
        """ë²¡í„° ë°±ì—…"""
        if method == "file":
            self._backup_to_file(vector_id, namespace, vector_data)
        else:
            self._backup_to_memory(vector_id, namespace, vector_data)
    
    def _backup_to_file(self, vector_id: str, namespace: str, vector_data: Dict[str, Any]):
        """íŒŒì¼ë¡œ ë°±ì—…"""
        os.makedirs(self.config.backup_dir, exist_ok=True)
        
        backup_data = {
            'vector_id': vector_id,
            'namespace': namespace,
            'vector_data': vector_data,
            'deleted_at': datetime.now().isoformat(),
            'expires_at': (datetime.now() + timedelta(minutes=self.config.backup_retention_minutes)).isoformat()
        }
        
        backup_file = os.path.join(self.config.backup_dir, f"{vector_id}.pkl")
        
        try:
            with open(backup_file, 'wb') as f:
                pickle.dump(backup_data, f)
            
            # ìë™ ì‚­ì œ íƒ€ì´ë¨¸ ì„¤ì •
            timer = threading.Timer(
                self.config.backup_retention_minutes * 60, 
                self._cleanup_backup_file, 
                args=[backup_file]
            )
            timer.daemon = True
            timer.start()
            
            print(f"ğŸ—‚ï¸ ë²¡í„° ë°±ì—… ì™„ë£Œ: {backup_file}")
            
        except Exception as e:
            print(f"âš ï¸ ë°±ì—… ì‹¤íŒ¨: {str(e)}")
    
    def _backup_to_memory(self, vector_id: str, namespace: str, vector_data: Dict[str, Any]):
        """ë©”ëª¨ë¦¬ë¡œ ë°±ì—…"""
        backup_data = {
            'vector_id': vector_id,
            'namespace': namespace,
            'vector_data': vector_data,
            'deleted_at': datetime.now(),
            'expires_at': datetime.now() + timedelta(minutes=self.config.backup_retention_minutes)
        }
        
        self._memory_backup[vector_id] = backup_data
        
        # ìë™ ì‚­ì œ íƒ€ì´ë¨¸ ì„¤ì •
        timer = threading.Timer(
            self.config.backup_retention_minutes * 60, 
            self._cleanup_memory_backup, 
            args=[vector_id]
        )
        timer.daemon = True
        timer.start()
        
        print(f"ğŸ’¾ ë²¡í„° ë©”ëª¨ë¦¬ ë°±ì—… ì™„ë£Œ: {vector_id}")
    
    def restore_vector(self, vector_id: str, pinecone_manager: PineconeManager) -> Tuple[bool, str]:
        """ë°±ì—…ëœ ë²¡í„° ë³µì›"""
        try:
            # ë©”ëª¨ë¦¬ ë°±ì—…ì—ì„œ í™•ì¸
            if vector_id in self._memory_backup:
                backup_data = self._memory_backup[vector_id]
                if datetime.now() <= backup_data['expires_at']:
                    return self._restore_from_backup(backup_data, pinecone_manager, vector_id)
                else:
                    del self._memory_backup[vector_id]
                    return False, f"âŒ ë³µì› ê¸°ê°„ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤: {vector_id}"
            
            # íŒŒì¼ ë°±ì—…ì—ì„œ í™•ì¸
            backup_file = os.path.join(self.config.backup_dir, f"{vector_id}.pkl")
            if os.path.exists(backup_file):
                with open(backup_file, 'rb') as f:
                    backup_data = pickle.load(f)
                
                expires_at = datetime.fromisoformat(backup_data['expires_at'])
                if datetime.now() <= expires_at:
                    result = self._restore_from_backup(backup_data, pinecone_manager, vector_id)
                    if result[0]:  # ì„±ê³µì‹œ ë°±ì—… íŒŒì¼ ì‚­ì œ
                        os.remove(backup_file)
                    return result
                else:
                    os.remove(backup_file)
                    return False, f"âŒ ë³µì› ê¸°ê°„ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤: {vector_id}"
            
            return False, f"âŒ ë°±ì—…ëœ ë²¡í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {vector_id}"
            
        except Exception as e:
            return False, f"âŒ ë²¡í„° ë³µì› ì‹¤íŒ¨: {str(e)}"
    
    def _restore_from_backup(self, backup_data: Dict, pinecone_manager: PineconeManager, 
                           vector_id: str) -> Tuple[bool, str]:
        """ë°±ì—… ë°ì´í„°ì—ì„œ ë²¡í„° ë³µì›"""
        try:
            index = pinecone_manager.get_index()
            vector_data = backup_data['vector_data']
            
            index.upsert(
                vectors=[(
                    vector_data['id'],
                    vector_data['values'],
                    vector_data['metadata']
                )],
                namespace=backup_data['namespace']
            )
            
            # ë©”ëª¨ë¦¬ ë°±ì—…ì—ì„œ ì œê±°
            if vector_id in self._memory_backup:
                del self._memory_backup[vector_id]
            
            return True, f"âœ… ë²¡í„° ë³µì› ì„±ê³µ: {vector_id}"
            
        except Exception as e:
            return False, f"âŒ ë²¡í„° ë³µì› ì¤‘ ì˜¤ë¥˜: {str(e)}"
    
    def _cleanup_backup_file(self, backup_file: str):
        """ë°±ì—… íŒŒì¼ ìë™ ì‚­ì œ"""
        try:
            if os.path.exists(backup_file):
                os.remove(backup_file)
                print(f"ğŸ—‘ï¸ ë°±ì—… íŒŒì¼ ìë™ ì‚­ì œ: {backup_file}")
        except Exception as e:
            print(f"âš ï¸ ë°±ì—… íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
    
    def _cleanup_memory_backup(self, vector_id: str):
        """ë©”ëª¨ë¦¬ ë°±ì—… ìë™ ì‚­ì œ"""
        try:
            if vector_id in self._memory_backup:
                del self._memory_backup[vector_id]
                print(f"ğŸ—‘ï¸ ë©”ëª¨ë¦¬ ë°±ì—… ìë™ ì‚­ì œ: {vector_id}")
        except Exception as e:
            print(f"âš ï¸ ë©”ëª¨ë¦¬ ë°±ì—… ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

class DataPreprocessor(ABC):
    """ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def get_required_fields(self) -> set:
        """ê° ë°ì´í„° íƒ€ì…ë³„ í•„ìˆ˜ í•„ë“œ ë°˜í™˜"""
        pass
    
    @abstractmethod
    def build_text(self, data: Dict[str, Any]) -> str:
        """ë°ì´í„°ë¥¼ ì„ë² ë”©ì„ ìœ„í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        pass
    
    @abstractmethod
    def build_metadata(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° êµ¬ì„±"""
        pass
    
    @abstractmethod
    def get_id(self, data: Dict[str, Any]) -> str:
        """ID í•„ë“œ ì¶”ì¶œ"""
        pass
    
    def preprocess(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ê³µí†µ ì „ì²˜ë¦¬ ë¡œì§"""
        return {
            "id": self.get_id(data),
            "text": self.build_text(data),
            "metadata": self.build_metadata(data)
        }

class BadgePreprocessor(DataPreprocessor):
    """ë°°ì§€ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def get_required_fields(self) -> set:
        return {'badge_id', 'name', 'issuer', 'criteria', 'skillsValidated'}
    
    def build_text(self, data: Dict[str, Any]) -> str:
        return f"""
        ë°°ì§€ëª…: {data.get('name', '')}
        ë°œê¸‰ì: {data.get('issuer', '')}
        ì„¤ëª…: {data.get('description', '')}
        ê¸°ì¤€: {data.get('criteria', '')}
        ì •ë ¬: {data.get('alignment', '')}
        ì·¨ì—… ê²°ê³¼: {data.get('employmentOutcome', '')}
        ê²€ì¦ëœ ê¸°ìˆ : {data.get('skillsValidated', '')}
        ì—­ëŸ‰: {data.get('competency', '')}
        í•™ìŠµ ê¸°íšŒ: {data.get('learningOpportunity', '')}
        """
    
    def build_metadata(self, data: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "name": data.get('name'),
            "issuer": data.get('issuer'),
            "skills": data.get('skillsValidated'),
            "competency": data.get('competency'),
            "related_badges": data.get('related_badges')
        }
    
    def get_id(self, data: Dict[str, Any]) -> str:
        return data.get('badge_id')

class UserPreprocessor(DataPreprocessor):
    """ì‚¬ìš©ì ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def get_required_fields(self) -> set:
        return {'user_id', 'goal', 'competency_level', 'learning_history'}
    
    def build_text(self, data: Dict[str, Any]) -> str:
        return f"""
        ì´ë¦„: {data.get('name', '')}
        ëª©í‘œ: {data.get('goal', '')}
        ê¸°ìˆ : {data.get('skills', '')}
        ì—­ëŸ‰ ìˆ˜ì¤€: {data.get('competency_level', '')}
        í•™ìŠµ ì´ë ¥: {data.get('learning_history', '')}
        ì·¨ì—… ì´ë ¥: {data.get('employment_history', '')}
        êµìœ¡ ìˆ˜ì¤€: {data.get('education_level', '')}
        ì°¸ì—¬ ì§€í‘œ: {data.get('engagement_metrics', '')}
        """
    
    def build_metadata(self, data: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "name": data.get('name'),
            "goal": data.get('goal'),
            "skills": data.get('skills'),
            "competency_level": data.get('competency_level'),
            "acquired_badges": data.get('acquired_badges'),
            "education_level": data.get('education_level')
        }
    
    def get_id(self, data: Dict[str, Any]) -> str:
        return data.get('user_id')

class DataTypeDetector:
    """ë°ì´í„° íƒ€ì… ê°ì§€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.badge_preprocessor = BadgePreprocessor()
        self.user_preprocessor = UserPreprocessor()
    
    def detect_data_type(self, data: Dict[str, Any], file_path: str = "") -> str:
        """ë°ì´í„° íƒ€ì…ì„ ê°ì§€"""
        data_keys = set(data.keys())
        
        badge_match = len(self.badge_preprocessor.get_required_fields().intersection(data_keys))
        user_match = len(self.user_preprocessor.get_required_fields().intersection(data_keys))
        
        if badge_match > user_match:
            return 'badge'
        elif user_match > badge_match:
            return 'user'
        else:
            # íŒŒì¼ëª…ìœ¼ë¡œë„ í™•ì¸
            filename = os.path.basename(file_path).lower()
            if 'badge' in filename:
                return 'badge'
            elif 'user' in filename:
                return 'user'
            else:
                raise ValueError(f"ë°ì´í„° íƒ€ì…ì„ ê²°ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

class DataEmbedder:
    """
    ë°ì´í„° ì„ë² ë”©ì„ ìœ„í•œ ë©”ì¸ í´ë˜ìŠ¤ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€)
    ì‹¤ì œë¡œëŠ” ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ì„ ì¡°í•©í•˜ì—¬ ì‘ë™
    """
    
    def __init__(self, 
                 pinecone_api_key: Optional[str] = None,
                 embedding_model: str = "multilingual-e5-large",
                 index_name: str = "openbadges",
                 config: Optional[EmbeddingConfig] = None):
        """
        ë°ì´í„° ì„ë² ë”©ì„ ìœ„í•œ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜ì„±ì„ ìœ„í•´ ê°œë³„ íŒŒë¼ë¯¸í„°ë„ ì§€ì›
        """
        if config is None:
            if pinecone_api_key is None:
                config = EmbeddingConfig.from_env()
            else:
                config = EmbeddingConfig(
                    pinecone_api_key=pinecone_api_key,
                    embedding_model=embedding_model,
                    index_name=index_name
                )
        
        self.config = config
        self.pinecone_manager = PineconeManager(config)
        self.backup_manager = VectorBackupManager(config)
        self.type_detector = DataTypeDetector()
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embeddings = PineconeEmbeddings(
            model=config.embedding_model,
            pinecone_api_key=config.pinecone_api_key
        )
        
        # ê¸°ì¡´ ì†ì„±ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´)
        self.embedding_model = config.embedding_model
        self.index_name = config.index_name
        self.pc = self.pinecone_manager.pc
        self._deleted_vectors_backup = self.backup_manager._memory_backup
    
    def _determine_namespace_from_id(self, vector_id: str) -> str:
        """ë²¡í„° IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê²°ì •"""
        if not vector_id:
            raise ValueError("ë²¡í„° IDê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
        if vector_id.upper().startswith('B'):
            return 'badge'
        elif vector_id.upper().startswith('U'):
            return 'user'
        else:
            raise ValueError(
                f"ì˜¬ë°”ë¥´ì§€ ì•Šì€ ID í˜•ì‹ì…ë‹ˆë‹¤. 'B' ë˜ëŠ” 'U'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤: "
                f"{vector_id}"
            )
    
    def _determine_data_type(self, file_path: str) -> str:
        """JSON íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ë°ì´í„° íƒ€ì… ê²°ì •"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return self.type_detector.detect_data_type(data, file_path)
        except Exception as e:
            raise ValueError(
                f"íŒŒì¼ì„ ì½ê±°ë‚˜ ë¶„ì„í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {file_path}, "
                f"ì˜¤ë¥˜: {str(e)}"
            )
    
    def preprocess_badge(self, badge_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë°°ì§€ ë°ì´í„° ì „ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜ì„±)"""
        return BadgePreprocessor().preprocess(badge_data)
    
    def preprocess_user(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë°ì´í„° ì „ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜ì„±)"""
        return UserPreprocessor().preprocess(user_data)
    
    def delete_vector(self, vector_id: str, backup_method: str = "memory") -> Tuple[bool, str]:
        """Pineconeì—ì„œ ë²¡í„°ë¥¼ ì‚­ì œ (30ë¶„ê°„ ë³µì› ê°€ëŠ¥í•˜ë„ë¡ ë°±ì—…)"""
        try:
            namespace = self._determine_namespace_from_id(vector_id)
            data_type = "ë°°ì§€" if namespace == "badge" else "ì‚¬ìš©ì"
            
            index = self.pinecone_manager.get_index()
            try:
                existing_vector = index.fetch(ids=[vector_id], namespace=namespace)
                if (not existing_vector.vectors or 
                    vector_id not in existing_vector.vectors):
                    return False, (f"âŒ í•´ë‹¹ {data_type}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: "
                                  f"{vector_id}")
                
                # ì‚­ì œ ì „ ë°±ì—…
                vector_data = existing_vector.vectors[vector_id]
                backup_data = {
                    'id': vector_id,
                    'values': vector_data.values,
                    'metadata': vector_data.metadata
                }
                
                self.backup_manager.backup_vector(
                    vector_id, namespace, backup_data, backup_method
                )
                
            except Exception as e:
                return False, f"âŒ ë²¡í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            
            # ë²¡í„° ì‚­ì œ
            try:
                index.delete(ids=[vector_id], namespace=namespace)
                return True, (f"âœ… {data_type} ì‚­ì œ ì„±ê³µ: {vector_id} "
                              f"(30ë¶„ê°„ ë³µì› ê°€ëŠ¥)")
                
            except Exception as e:
                return False, f"âŒ {data_type} ì‚­ì œ ì‹¤íŒ¨: {str(e)}"
                
        except ValueError as e:
            return False, f"âŒ {str(e)}"
        except Exception as e:
            return False, f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
    
    def restore_vector(self, vector_id: str) -> Tuple[bool, str]:
        """ë°±ì—…ëœ ë²¡í„°ë¥¼ ë³µì›"""
        return self.backup_manager.restore_vector(vector_id, self.pinecone_manager)
    
    def upsert_vector(self, file_path: str):
        """íŠ¹ì • JSON íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ Pineconeì— ë²¡í„°ë¥¼ upsert"""
        try:
            # íŒŒì¼ íƒ€ì… í™•ì¸
            data_type = self._determine_data_type(file_path)
            print(f"íŒŒì¼ íƒ€ì… í™•ì¸: {data_type}")
            
            # íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if data_type == 'badge':
                processed_item = self.preprocess_badge(data)
            else:
                processed_item = self.preprocess_user(data)
            
            # ë™ì¼í•œ IDê°€ ìˆëŠ”ì§€ í™•ì¸
            index = self.pinecone_manager.get_index()
            vector_id = processed_item["id"]
            
            try:
                existing_vector = index.fetch(ids=[vector_id], namespace=data_type)
                if existing_vector.vectors:
                    print(f"ë²¡í„° ì—…ë°ì´íŠ¸: ID {vector_id} (ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {data_type})")
                else:
                    print(f"ìƒˆ ë²¡í„° ì‚½ì…: ID {vector_id} (ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {data_type})")
            except Exception:
                print(f"ìƒˆ ë²¡í„° ì‚½ì…: ID {vector_id} (ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {data_type})")
            
            # ë²¡í„° ì„ë² ë”© ìƒì„±
            vector = self.embeddings.embed_query(processed_item["text"])
            
            # Pineconeì— upsert
            try:
                index.upsert(
                    vectors=[(vector_id, vector, processed_item["metadata"])],
                    namespace=data_type
                )
                
                # ì„±ê³µ ë©”ì‹œì§€ ì¶œë ¥
                name = processed_item["metadata"].get("name", "ì´ë¦„ ì—†ìŒ")
                print(f"âœ… upsert ì„±ê³µ: {name} (ID: {vector_id}, íƒ€ì…: {data_type})")
                
            except Exception as e:
                print(f"âŒ upsert ì‹¤íŒ¨: ID {vector_id}, ì˜¤ë¥˜: {str(e)}")
                
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜: {str(e)}")
    
    def upsert_manually_all(self, data_dir: str, data_type: str):
        """ë°ì´í„° ìˆ˜ë™ ì„ë² ë”©ì„ ìœ„í•´ íŠ¹ì • ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  json íŒŒì¼ì„ ì„ë² ë”© í›„ ì €ì¥"""
        if data_type not in ['badge', 'user']:
            raise ValueError("data_typeì€ 'badge' ë˜ëŠ” 'user'ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
        # íŒŒì¼ íŒ¨í„´ ì„¤ì •
        file_pattern = f"{data_type}_*.json"
        data_files = glob.glob(os.path.join(data_dir, file_pattern))
        processed_data = []
        
        # ì „ì²˜ë¦¬ê¸° ì„ íƒ
        if data_type == 'badge':
            preprocessor = BadgePreprocessor()
        else:
            preprocessor = UserPreprocessor()
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        for data_file in data_files:
            with open(data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                processed_item = preprocessor.preprocess(data)
                processed_data.append(processed_item)
        
        # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ë° Pineconeì— ì €ì¥
        texts = [item["text"] for item in processed_data]
        metadatas = [item["metadata"] for item in processed_data]
        ids = [item["id"] for item in processed_data]
        
        # Pineconeì— ë°ì´í„° ì €ì¥
        index = self.pinecone_manager.get_index()
        for text, metadata, id in zip(texts, metadatas, ids):
            vector = self.embeddings.embed_query(text)
            index.upsert(
                vectors=[(id, vector, metadata)],
                namespace=data_type
            )
            print(f"{data_type} ë°ì´í„° ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì™„ë£Œ: {id}")
        
        print(f"{data_type} ë°ì´í„° ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì™„ë£Œ: {len(texts)}ê°œ")

    # ê¸°ì¡´ ë©”ì†Œë“œë“¤ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
    def _initialize_index(self):
        """ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì†Œë“œ"""
        self.pinecone_manager._initialize_index()
    
    def _backup_vector_to_file(self, vector_id: str, namespace: str, vector_data: Dict[str, Any]):
        """ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì†Œë“œ"""
        self.backup_manager._backup_to_file(vector_id, namespace, vector_data)
    
    def _backup_vector_to_memory(self, vector_id: str, namespace: str, vector_data: Dict[str, Any]):
        """ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì†Œë“œ"""
        self.backup_manager._backup_to_memory(vector_id, namespace, vector_data)

def main():
    """
    /data ì˜ json ë°°ì§€/ìœ ì € íŒŒì¼ ì„ë² ë”©
    """
    # ì„¤ì •ì„ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
    config = EmbeddingConfig.from_env()
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
    data_dir = "data/json"
    
    # ì„ë² ë” ì´ˆê¸°í™”
    embedder = DataEmbedder(config=config)
    
    # ë°°ì§€ ë°ì´í„° ì²˜ë¦¬
    embedder.upsert_manually_all(os.path.join(data_dir, "badge"), "badge")
    
    # ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬
    embedder.upsert_manually_all(os.path.join(data_dir, "user"), "user")

if __name__ == "__main__":
    main()